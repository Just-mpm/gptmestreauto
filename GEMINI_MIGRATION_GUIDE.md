# ğŸš€ Guia de MigraÃ§Ã£o para Google Gemini 2.5 Flash

## ğŸ“‹ VisÃ£o Geral

Este guia documenta a migraÃ§Ã£o do GPT Mestre AutÃ´nomo para usar o Google Gemini 2.5 Flash como provider de LLM, mantendo compatibilidade com Anthropic Claude.

## ğŸ¯ O que foi implementado

### 1. **Multi-Provider Support**
- âœ… Sistema agora suporta tanto Google Gemini quanto Anthropic Claude
- âœ… FÃ¡cil troca entre providers via variÃ¡vel de ambiente
- âœ… Compatibilidade total mantida com cÃ³digo existente

### 2. **LLM Factory Pattern**
- âœ… Novo mÃ³dulo `utils/llm_factory.py` para abstraÃ§Ã£o de LLMs
- âœ… Suporte unificado para diferentes providers
- âœ… ConfiguraÃ§Ã£o automÃ¡tica baseada em environment

### 3. **AtualizaÃ§Ãµes Realizadas**
- âœ… `config.py` - Suporte para ambos os providers
- âœ… `requirements.txt` - DependÃªncias do Google Gemini adicionadas
- âœ… `base_agent_v2.py` - Usa novo sistema LLM Factory
- âœ… `carlos.py` - Migrado para multi-provider
- âœ… `deep_agent_v2.py` - Suporte Gemini em cliente direto

## ğŸ”§ ConfiguraÃ§Ã£o

### 1. **Instalar DependÃªncias**

```bash
pip install -r requirements.txt
```

### 2. **Configurar VariÃ¡veis de Ambiente**

Crie ou edite o arquivo `.env` na raiz do projeto:

```env
# Escolha o provider (gemini ou anthropic)
LLM_PROVIDER=gemini

# Para usar Google Gemini
GOOGLE_API_KEY=sua_chave_api_gemini_aqui

# Para usar Anthropic (opcional, apenas se quiser manter compatibilidade)
ANTHROPIC_API_KEY=sua_chave_anthropic_aqui
```

### 3. **Obter API Key do Google Gemini**

1. Acesse: https://makersuite.google.com/app/apikey
2. Clique em "Create API Key"
3. Copie a chave gerada
4. Cole no arquivo `.env` como `GOOGLE_API_KEY`

## ğŸ”„ Como Alternar Entre Providers

### Usar Google Gemini (PadrÃ£o)
```env
LLM_PROVIDER=gemini
GOOGLE_API_KEY=sua_chave_aqui
```

### Usar Anthropic Claude
```env
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sua_chave_aqui
```

## ğŸ“Š ComparaÃ§Ã£o de Modelos

| Feature | Gemini 2.5 Flash | Claude 3.5 Haiku |
|---------|------------------|------------------|
| Max Tokens | 8192 | 4000 |
| Velocidade | âš¡ Muito RÃ¡pido | âš¡ RÃ¡pido |
| Custo | ğŸ’° Mais Barato | ğŸ’° Moderado |
| Web Search | âœ… Suportado | âœ… Suportado |
| Streaming | âœ… Sim | âœ… Sim |

## ğŸš¨ ConfiguraÃ§Ãµes de SeguranÃ§a (Gemini)

O sistema jÃ¡ estÃ¡ configurado com nÃ­veis seguros:

```python
GEMINI_SAFETY_SETTINGS = [
    {
        "category": "HARM_CATEGORY_HARASSMENT",
        "threshold": "BLOCK_ONLY_HIGH"
    },
    {
        "category": "HARM_CATEGORY_HATE_SPEECH", 
        "threshold": "BLOCK_ONLY_HIGH"
    },
    {
        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "threshold": "BLOCK_ONLY_HIGH"
    },
    {
        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
        "threshold": "BLOCK_ONLY_HIGH"
    }
]
```

## ğŸ› ï¸ Uso ProgramÃ¡tico

### Criar LLM com configuraÃ§Ã£o padrÃ£o
```python
from utils.llm_factory import create_llm

# Usa provider do config.py
llm = create_llm()
response = llm.invoke("OlÃ¡!")
print(response.content)
```

### ForÃ§ar provider especÃ­fico
```python
# ForÃ§ar Gemini
llm = create_llm(provider="gemini")

# ForÃ§ar Anthropic
llm = create_llm(provider="anthropic")
```

### Personalizar parÃ¢metros
```python
llm = create_llm(
    temperature=0.9,  # Mais criativo
    max_tokens=2000   # Limitar tokens
)
```

## ğŸ“ AlteraÃ§Ãµes no CÃ³digo

### Para Desenvolvedores

1. **BaseAgentV2** agora tenta usar `llm_factory` primeiro
2. **Carlos** usa o novo sistema com fallback para compatibilidade
3. **DeepAgent** suporta Gemini em modo cliente direto

### Compatibilidade

- âœ… Todo cÃ³digo existente continua funcionando
- âœ… VariÃ¡veis legadas mantidas (`CLAUDE_MODEL`, etc.)
- âœ… Fallback automÃ¡tico se `llm_factory` nÃ£o disponÃ­vel

## ğŸ¯ Modelo Recomendado

```
models/gemini-2.5-flash-preview-05-20
```

Este Ã© o modelo Gemini 2.5 Flash mais recente, otimizado para:
- âš¡ Velocidade extrema
- ğŸ’° Custo reduzido
- ğŸ§  Qualidade comparÃ¡vel ao Claude
- ğŸ“ Suporte para 8K tokens

## ğŸ› Troubleshooting

### Erro: "GOOGLE_API_KEY nÃ£o encontrada"
- Verifique se o arquivo `.env` existe
- Confirme que a chave estÃ¡ configurada corretamente
- Reinicie o aplicativo apÃ³s configurar

### Erro: "LLM_PROVIDER invÃ¡lido"
- Use apenas "gemini" ou "anthropic" como valor
- Verifique ortografia no `.env`

### Respostas diferentes entre providers
- Normal - cada modelo tem seu estilo
- Ajuste `temperature` se necessÃ¡rio
- Gemini tende a ser mais conciso

## ğŸ“š Recursos Adicionais

- [DocumentaÃ§Ã£o Google Gemini](https://ai.google.dev/docs)
- [Gemini API Reference](https://ai.google.dev/api/python/google/generativeai)
- [PreÃ§os Gemini](https://ai.google.dev/pricing)

## âœ… Checklist de MigraÃ§Ã£o

- [ ] Instalar dependÃªncias: `pip install -r requirements.txt`
- [ ] Obter API Key do Google Gemini
- [ ] Configurar `.env` com `LLM_PROVIDER=gemini`
- [ ] Adicionar `GOOGLE_API_KEY` ao `.env`
- [ ] Testar sistema: `python config.py`
- [ ] Verificar logs para confirmar "Gemini configurado"

## ğŸ‰ Pronto!

Seu sistema agora estÃ¡ usando Google Gemini 2.5 Flash! 

Para voltar ao Claude a qualquer momento, apenas mude:
```env
LLM_PROVIDER=anthropic
```