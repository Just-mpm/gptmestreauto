"""
Agente Carlos v2.0 - Interface Principal com Mem√≥ria Vetorial Integrada
Vers√£o FINAL: Sistema de mem√≥ria + auditoria + facilidade de uso
"""

import json
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any

from agents.base_agent import BaseAgent
from utils.logger import get_logger

logger = get_logger(__name__)

class CarlosAgent(BaseAgent):
    """
    Carlos v2.0 - Interface Principal com Mem√≥ria Inteligente
    
    ‚ú® NOVIDADES v2.0:
    - üß† Mem√≥ria vetorial integrada (ChromaDB)
    - üîç Busca sem√¢ntica em conversas anteriores
    - üìö Aprendizado cont√≠nuo autom√°tico
    - ü§ñ Reflexor v1.5+ para auditoria
    - üí° Respostas contextualizadas
    """
    
    def __init__(self, reflexor_ativo: bool = True, memoria_ativa: bool = True, llm=None):
        super().__init__(
            name="Carlos",
            description="Interface principal v2.0 com mem√≥ria vetorial inteligente"
        )
        
        # Sistema de mem√≥ria
        self.memoria_ativa = memoria_ativa
        self.memory_manager = None
        
        if self.memoria_ativa:
            try:
                from memory.vector_store import get_memory_manager
                self.memory_manager = get_memory_manager()
                if self.memory_manager.memory_active:
                    logger.info("üß† Mem√≥ria vetorial ativada com sucesso!")
                else:
                    logger.warning("‚ö†Ô∏è Mem√≥ria vetorial n√£o dispon√≠vel")
                    self.memoria_ativa = False
            except ImportError:
                logger.warning("‚ö†Ô∏è M√≥dulo de mem√≥ria n√£o encontrado")
                self.memoria_ativa = False
        
        # Configura√ß√£o do LLM
        if llm is None:
            self._inicializar_llm()
        else:
            self.llm = llm
        
        # Sistema de Reflexor
        self.reflexor_ativo = reflexor_ativo
        self.reflexor = None
        if self.reflexor_ativo:
            self._inicializar_reflexor()
        
        # Mem√≥ria da sess√£o (backup)
        self.conversa_memoria = []
        self.contexto_memoria = {}
        
        # Estat√≠sticas v2.0
        self.stats.update({
            "total_respostas": 0,
            "respostas_com_memoria": 0,
            "respostas_sem_memoria": 0,
            "busca_semantica_usado": 0,
            "contexto_recuperado": 0,
            "aprendizados_salvos": 0,
            "score_medio_qualidade": 0.0
        })
        
        # Compatibilidade com vers√µes anteriores
        self.stats_carlos = self.stats
        self.stats_ecossistema = {"versao": "2.0"}
        
        logger.info(f"ü§ñ Carlos v2.0 inicializado - Mem√≥ria: {'‚úÖ' if self.memoria_ativa else '‚ùå'}")
    
    def _inicializar_llm(self):
        """Inicializa o LLM com configura√ß√µes padr√£o"""
        try:
            from langchain_anthropic import ChatAnthropic
            import config
            
            if not config.ANTHROPIC_API_KEY:
                raise ValueError("ANTHROPIC_API_KEY n√£o configurada no arquivo .env")
            
            self.llm = ChatAnthropic(
                model=config.CLAUDE_MODEL,
                max_tokens=config.CLAUDE_MAX_TOKENS,
                temperature=config.CLAUDE_TEMPERATURE,
                anthropic_api_key=config.ANTHROPIC_API_KEY,
            )
            logger.info("üîó LLM Claude inicializado para Carlos v2.0")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar LLM: {e}")
            raise
    
    def _inicializar_reflexor(self):
        """Inicializa o Reflexor se dispon√≠vel"""
        try:
            from agents.reflexor import AgenteReflexor
            self.reflexor = AgenteReflexor(llm=self.llm)
            logger.info("üîç Reflexor v1.5+ ativado")
        except ImportError:
            logger.warning("‚ö†Ô∏è Reflexor n√£o dispon√≠vel")
            self.reflexor = None
            self.reflexor_ativo = False
        except Exception as e:
            logger.error(f"‚ùå Erro ao ativar Reflexor: {e}")
            self.reflexor = None
            self.reflexor_ativo = False
    
    def processar(self, mensagem: str, contexto: Optional[Dict] = None) -> str:
        """
        Processa mensagem com sistema de mem√≥ria vetorial v2.0
        
        üîÑ FLUXO v2.0:
        1. Verifica comandos especiais
        2. üß† Busca contexto na mem√≥ria vetorial
        3. üí≠ Gera resposta enriquecida com contexto
        4. üîç Auditoria com Reflexor v1.5+
        5. üíæ Salva na mem√≥ria vetorial
        """
        try:
            # 1. Verificar comandos especiais
            if mensagem.startswith('/'):
                resposta = self._processar_comando(mensagem)
                self._salvar_na_memoria_sessao(mensagem, resposta, contexto)
                return resposta
            
            # 2. üß† Recuperar contexto da mem√≥ria vetorial
            contexto_recuperado = ""
            if self.memoria_ativa and self.memory_manager:
                try:
                    contexto_recuperado = self.memory_manager.recall_context(mensagem)
                    self.stats["busca_semantica_usado"] += 1
                    
                    # Verificar se encontrou contexto relevante
                    if len(contexto_recuperado) > 50 and "CONVERSAS ANTERIORES" in contexto_recuperado:
                        self.stats["contexto_recuperado"] += 1
                        logger.debug("üß† Contexto relevante encontrado!")
                except Exception as e:
                    logger.error(f"‚ö†Ô∏è Erro ao buscar contexto: {e}")
                    contexto_recuperado = ""
            
            # 3. üí≠ Gerar resposta com contexto enriquecido
            prompt = self._construir_prompt_com_memoria(mensagem, contexto, contexto_recuperado)
            resposta = self._gerar_resposta(prompt)
            
            # 4. üîç Sistema de auditoria com Reflexor v1.5+
            if self.reflexor_ativo and self.reflexor:
                try:
                    reflexao = self.reflexor.analisar_resposta(
                        pergunta=mensagem,
                        resposta=resposta,
                        contexto=contexto or {}
                    )
                    
                    self._atualizar_stats_reflexao(reflexao)
                    
                    # Se score baixo, tentar melhorar
                    if reflexao.score_qualidade < 6:
                        logger.info(f"‚ö†Ô∏è Score baixo ({reflexao.score_qualidade}), melhorando...")
                        resposta_melhorada = self._melhorar_resposta(mensagem, resposta, reflexao)
                        if resposta_melhorada:
                            resposta = resposta_melhorada
                    
                    # Salvar aprendizado se relevante
                    if reflexao.score_qualidade >= 8 and len(mensagem) > 30:
                        self._salvar_aprendizado_automatico(mensagem, resposta, reflexao)
                    
                except Exception as e:
                    logger.error(f"‚ö†Ô∏è Erro na auditoria: {e}")
            
            # 5. üíæ Salvar na mem√≥ria vetorial
            if self.memoria_ativa and self.memory_manager:
                try:
                    session_id = contexto.get('session_id') if contexto else None
                    self.memory_manager.remember_conversation(
                        user_input=mensagem,
                        assistant_response=resposta,
                        agent_name="Carlos",
                        session_id=session_id
                    )
                    self.stats["respostas_com_memoria"] += 1
                    logger.debug("üíæ Conversa salva na mem√≥ria")
                except Exception as e:
                    logger.error(f"‚ö†Ô∏è Erro ao salvar: {e}")
                    self.stats["respostas_sem_memoria"] += 1
            else:
                self.stats["respostas_sem_memoria"] += 1
            
            # 6. Backup na mem√≥ria da sess√£o
            self._salvar_na_memoria_sessao(mensagem, resposta, contexto)
            
            # 7. Atualizar estat√≠sticas
            self.update_stats(success=True)
            self.stats["total_respostas"] += 1
            
            return resposta
            
        except Exception as e:
            logger.error(f"‚ùå Erro no processamento v2.0: {e}")
            self.update_stats(success=False)
            return f"‚ùå Erro interno: {str(e)}"
    
    def _construir_prompt_com_memoria(self, mensagem: str, contexto: Optional[Dict], 
                                    contexto_memoria: str) -> str:
        """Constr√≥i prompt v2.0 enriquecido com contexto da mem√≥ria"""
        
        prompt_base = f"""Voc√™ √© Carlos v2.0, agente principal do GPT Mestre Aut√¥nomo.

ü§ñ CARACTER√çSTICAS v2.0:
- Interface inteligente e proativa
- Sistema de mem√≥ria vetorial ativo
- Respostas baseadas em contexto hist√≥rico
- Aprendizado cont√≠nuo e auditoria integrada

üß† CONTEXTO DA SESS√ÉO ATUAL:
{self._obter_contexto_recente()}"""

        # Adicionar contexto da mem√≥ria vetorial se dispon√≠vel
        if contexto_memoria and len(contexto_memoria) > 50:
            prompt_base += f"""

{contexto_memoria}"""
        
        prompt_base += f"""

üí¨ PERGUNTA ATUAL:
{mensagem}

üìã INSTRU√á√ïES v2.0:
- Use o contexto hist√≥rico para respostas mais precisas
- Mantenha continuidade com conversas anteriores
- Seja natural e direto
- Aplique aprendizados relevantes

Responda de forma √∫til e contextualizada:"""
        
        return prompt_base
    
    def _salvar_aprendizado_automatico(self, mensagem: str, resposta: str, reflexao):
        """v2.0: Salva aprendizados importantes automaticamente"""
        try:
            if not self.memory_manager or not self.memoria_ativa:
                return
            
            # Identificar categoria
            categoria = self._identificar_categoria(mensagem)
            
            # Criar aprendizado
            aprendizado = f"P: {mensagem[:100]}{'...' if len(mensagem) > 100 else ''}\nR: {resposta[:200]}{'...' if len(resposta) > 200 else ''}\nScore: {reflexao.score_qualidade:.1f}/10"
            
            self.memory_manager.remember_learning(
                text=aprendizado,
                category=categoria,
                agent="Carlos_v2"
            )
            
            self.stats["aprendizados_salvos"] += 1
            logger.info(f"üìö Aprendizado salvo: {categoria}")
            
        except Exception as e:
            logger.error(f"‚ö†Ô∏è Erro ao salvar aprendizado: {e}")
    
    def _identificar_categoria(self, mensagem: str) -> str:
        """Identifica categoria do aprendizado"""
        msg_lower = mensagem.lower()
        
        if any(word in msg_lower for word in ["produto", "vender", "comprar"]):
            return "produto"
        elif any(word in msg_lower for word in ["pre√ßo", "custo", "valor"]):
            return "preco"
        elif any(word in msg_lower for word in ["an√∫ncio", "copy", "marketing"]):
            return "marketing"
        elif any(word in msg_lower for word in ["como", "explicar", "tutorial"]):
            return "tutorial"
        else:
            return "geral"
    
    # ===== COMANDOS v2.0 ATUALIZADOS =====
    
    def _comando_status(self) -> str:
        """Status v2.0 com informa√ß√µes de mem√≥ria"""
        try:
            reflexor_status = "üü¢ v1.5+" if self.reflexor_ativo else "üî¥ Inativo"
            memoria_status = "üß† Ativa" if self.memoria_ativa else "‚ùå Inativa"
            
            info_base = f"""üìä **CARLOS v2.0 - STATUS DO SISTEMA**

ü§ñ **Carlos:** v2.0 Operacional
üîç **Reflexor:** {reflexor_status}
üß† **Mem√≥ria Vetorial:** {memoria_status}
üîó **LLM:** Claude 3 Haiku
üì± **Interface:** Streamlit
"""
            
            # Estat√≠sticas de mem√≥ria
            if self.memoria_ativa and self.memory_manager:
                try:
                    stats = self.memory_manager.get_stats()
                    if stats.get('memory_active'):
                        vm = stats['vector_memory']
                        info_base += f"""
üß† **MEM√ìRIA VETORIAL:**
‚Ä¢ Conversas indexadas: {vm.get('conversations', 0)}
‚Ä¢ Aprendizados salvos: {vm.get('learnings', 0)}
‚Ä¢ Total documentos: {vm.get('total_documents', 0)}
‚Ä¢ Modelo: {vm.get('embedding_model', 'N/A')}"""
                except:
                    info_base += "\nüß† **MEM√ìRIA:** Erro ao carregar stats"
            
            # Estat√≠sticas da sess√£o
            info_base += f"""

üìà **ESTAT√çSTICAS v2.0:**
‚Ä¢ Total respostas: {self.stats.get('total_respostas', 0)}
‚Ä¢ Com mem√≥ria: {self.stats.get('respostas_com_memoria', 0)}
‚Ä¢ Buscas sem√¢nticas: {self.stats.get('busca_semantica_usado', 0)}
‚Ä¢ Contexto usado: {self.stats.get('contexto_recuperado', 0)}
‚Ä¢ Aprendizados: {self.stats.get('aprendizados_salvos', 0)}

‚è∞ **Uptime:** {datetime.now().strftime('%H:%M:%S')}"""
            
            return info_base
            
        except Exception as e:
            return f"üìä **CARLOS v2.0 - STATUS** (Erro: {str(e)[:100]})"
    
    def _comando_memoria(self) -> str:
        """Comando mem√≥ria v2.0"""
        try:
            sessao_items = len(self.conversa_memoria)
            
            info = f"""üß† **MEM√ìRIA v2.0 - SISTEMA INTELIGENTE**

üì± **Mem√≥ria da Sess√£o:** {sessao_items} intera√ß√µes"""
            
            if self.memoria_ativa and self.memory_manager:
                try:
                    stats = self.memory_manager.get_stats()
                    if stats.get('memory_active'):
                        vm = stats['vector_memory']
                        info += f"""

üß† **Mem√≥ria Vetorial (ChromaDB):**
‚Ä¢ Status: ‚úÖ Ativa e funcionando
‚Ä¢ Conversas salvas: {vm.get('conversations', 0)}
‚Ä¢ Aprendizados: {vm.get('learnings', 0)}
‚Ä¢ Modelo de busca: {vm.get('embedding_model', 'N/A')}
‚Ä¢ Localiza√ß√£o: {vm.get('storage_path', 'N/A')}

üìä **Performance da Mem√≥ria:**
‚Ä¢ Buscas realizadas: {self.stats.get('busca_semantica_usado', 0)}
‚Ä¢ Contexto encontrado: {self.stats.get('contexto_recuperado', 0)}
‚Ä¢ Taxa de sucesso: {(self.stats.get('contexto_recuperado', 0) / max(1, self.stats.get('busca_semantica_usado', 1)) * 100):.1f}%"""
                    else:
                        info += f"\nüß† **Mem√≥ria Vetorial:** ‚ùå {stats.get('error', 'Erro desconhecido')}"
                except Exception as e:
                    info += f"\nüß† **Mem√≥ria Vetorial:** ‚ö†Ô∏è Erro: {str(e)[:100]}"
            else:
                info += "\nüß† **Mem√≥ria Vetorial:** ‚ùå Desativada"
            
            # √öltimas intera√ß√µes
            if self.conversa_memoria:
                info += "\n\nüìã **√öltimas Intera√ß√µes:**"
                for item in self.conversa_memoria[-3:]:
                    preview = item['pergunta'][:40] + "..." if len(item['pergunta']) > 40 else item['pergunta']
                    info += f"\n‚Ä¢ {item['timestamp']}: {preview}"
            
            return info
            
        except Exception as e:
            return f"üß† **MEM√ìRIA v2.0** - Erro: {str(e)}"
    
    def _comando_help(self) -> str:
        """Help v2.0 atualizado"""
        return """ü§ñ **CARLOS v2.0 - SISTEMA INTELIGENTE COM MEM√ìRIA**

üß† **NOVIDADES v2.0:**
‚Ä¢ **Mem√≥ria Vetorial**: Lembro de TODAS as nossas conversas
‚Ä¢ **Busca Sem√¢ntica**: Encontro automaticamente contexto relevante
‚Ä¢ **Aprendizado Cont√≠nuo**: Cada conversa me torna mais inteligente
‚Ä¢ **Reflexor v1.5+**: Auditoria autom√°tica de qualidade

üí¨ **Como usar:**
Converse naturalmente! Automaticamente:
‚Ä¢ Busco conversas similares anteriores
‚Ä¢ Recupero aprendizados relevantes
‚Ä¢ Aplico contexto para respostas melhores
‚Ä¢ Salvo novos conhecimentos importantes

üìã **Comandos Especiais:**
‚Ä¢ `/help` - Esta ajuda completa
‚Ä¢ `/status` - Status do sistema com mem√≥ria
‚Ä¢ `/memory` - Informa√ß√µes detalhadas da mem√≥ria
‚Ä¢ `/clear` - Limpar sess√£o (mant√©m mem√≥ria vetorial)
‚Ä¢ `/agents` - Lista de agentes dispon√≠veis
‚Ä¢ `/reflexor` - Status do sistema de auditoria
‚Ä¢ `/stats` - Estat√≠sticas completas v2.0

üîç **Funcionalidades Avan√ßadas:**
‚Ä¢ Continuidade entre sess√µes diferentes
‚Ä¢ Respostas contextualizadas baseadas no hist√≥rico
‚Ä¢ Detec√ß√£o autom√°tica de padr√µes e aprendizados
‚Ä¢ Sistema de qualidade em tempo real
‚Ä¢ Mem√≥ria persistente local (ChromaDB)

‚ö° **Exemplos de Uso:**
‚Ä¢ "Volte ao assunto que falamos sobre pre√ßos"
‚Ä¢ "Como ficou aquela an√°lise de produto?"
‚Ä¢ "Lembra do que discutimos sobre marketing?"

üéØ **O Carlos v2.0 √© muito mais inteligente porque nunca esquece!**"""
    
    def _comando_clear(self) -> str:
        """Clear v2.0 - preserva mem√≥ria vetorial"""
        items_removidos = len(self.conversa_memoria)
        self.conversa_memoria.clear()
        self.contexto_memoria.clear()
        
        return f"""üóëÔ∏è **SESS√ÉO LIMPA v2.0**

‚úÖ **Removido da sess√£o:**
‚Ä¢ {items_removidos} intera√ß√µes tempor√°rias
‚Ä¢ Cache de contexto da sess√£o atual

üß† **Preservado na mem√≥ria vetorial:**
‚Ä¢ Todas as conversas anteriores
‚Ä¢ Aprendizados acumulados
‚Ä¢ Conhecimento hist√≥rico

üí° **Nota:** A mem√≥ria vetorial √© permanente e continua ativa!
Para acessar conversas anteriores, apenas converse normalmente."""
    
    def _comando_reflexor(self) -> str:
        """Status do Reflexor v2.0"""
        if not self.reflexor_ativo or not self.reflexor:
            return "üî¥ **REFLEXOR v1.5+ - INATIVO**"
        
        try:
            return f"""üîç **REFLEXOR v1.5+ - STATUS AVAN√áADO**

‚úÖ **Configura√ß√£o:**
‚Ä¢ Status: üü¢ ATIVO e Integrado
‚Ä¢ Vers√£o: v1.5+ com mem√≥ria
‚Ä¢ Modo: Auditoria autom√°tica
‚Ä¢ Auto-aprendizado: ‚úÖ Ativo

üìä **Estat√≠sticas v2.0:**
‚Ä¢ Score m√©dio: {self.stats.get('score_medio_qualidade', 0.0):.1f}/10
‚Ä¢ Respostas auditadas: {self.stats.get('successful_interactions', 0)}
‚Ä¢ Melhorias aplicadas: {self.stats.get('respostas_melhoradas', 0)}
‚Ä¢ Aprendizados gerados: {self.stats.get('aprendizados_salvos', 0)}

üß† **Integra√ß√£o com Mem√≥ria:**
‚Ä¢ Salva automaticamente respostas de alta qualidade
‚Ä¢ Aprende padr√µes de sucesso
‚Ä¢ Melhora respostas com base no hist√≥rico

‚è∞ **√öltima verifica√ß√£o:** {datetime.now().strftime('%H:%M:%S')}"""
            
        except Exception as e:
            return f"üîç **REFLEXOR v1.5+** - Erro: {str(e)[:100]}"
    
    def _comando_stats(self) -> str:
        """Stats v2.0 completas"""
        try:
            total = self.stats.get('total_interactions', 0)
            sucessos = self.stats.get('successful_interactions', 0)
            taxa_sucesso = (sucessos / max(1, total)) * 100
            
            return f"""üìà **ESTAT√çSTICAS COMPLETAS v2.0**

üéØ **Performance Geral:**
‚Ä¢ Taxa de sucesso: {taxa_sucesso:.1f}%
‚Ä¢ Total intera√ß√µes: {total}
‚Ä¢ Sucessos: {sucessos}
‚Ä¢ Erros: {self.stats.get('errors', 0)}

üß† **Sistema de Mem√≥ria:**
‚Ä¢ Respostas com mem√≥ria: {self.stats.get('respostas_com_memoria', 0)}
‚Ä¢ Respostas sem mem√≥ria: {self.stats.get('respostas_sem_memoria', 0)}
‚Ä¢ Buscas sem√¢nticas: {self.stats.get('busca_semantica_usado', 0)}
‚Ä¢ Contexto recuperado: {self.stats.get('contexto_recuperado', 0)}
‚Ä¢ Taxa de contexto: {(self.stats.get('contexto_recuperado', 0) / max(1, self.stats.get('busca_semantica_usado', 1)) * 100):.1f}%

üîç **Sistema de Auditoria:**
‚Ä¢ Score m√©dio qualidade: {self.stats.get('score_medio_qualidade', 0.0):.1f}/10
‚Ä¢ Aprendizados salvos: {self.stats.get('aprendizados_salvos', 0)}

üì± **Sess√£o Atual:**
‚Ä¢ Conversas na sess√£o: {len(self.conversa_memoria)}
‚Ä¢ Uptime: {datetime.now().strftime('%H:%M:%S')}

üöÄ **Vers√£o:** Carlos v2.0 com Mem√≥ria Inteligente"""
        
        except Exception as e:
            return f"üìà **ESTAT√çSTICAS v2.0** - Erro: {str(e)[:100]}"
    
    # ===== M√âTODOS DE SUPORTE =====
    
    def _obter_contexto_recente(self) -> str:
        """Obt√©m contexto das conversas recentes da sess√£o"""
        if not self.conversa_memoria:
            return "Nova sess√£o iniciada."
        
        contexto_items = []
        for item in self.conversa_memoria[-2:]:  # √öltimas 2 da sess√£o
            pergunta_short = item['pergunta'][:80] + "..." if len(item['pergunta']) > 80 else item['pergunta']
            resposta_short = item['resposta'][:80] + "..." if len(item['resposta']) > 80 else item['resposta']
            contexto_items.append(f"P: {pergunta_short}\nR: {resposta_short}")
        
        return "\n".join(contexto_items)
    
    def _salvar_na_memoria_sessao(self, mensagem: str, resposta: str, contexto: Optional[Dict] = None):
        """Salva na mem√≥ria tempor√°ria da sess√£o"""
        interacao = {
            "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "pergunta": mensagem,
            "resposta": resposta,
            "contexto": contexto
        }
        
        self.conversa_memoria.append(interacao)
        
        # Manter apenas √∫ltimas 15 na sess√£o
        if len(self.conversa_memoria) > 15:
            self.conversa_memoria = self.conversa_memoria[-15:]
    
    def _gerar_resposta(self, prompt: str) -> str:
        """Gera resposta usando o LLM"""
        try:
            resposta = self.llm.invoke(prompt)
            return resposta.content if hasattr(resposta, 'content') else str(resposta)
        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar resposta: {e}")
            return "Desculpe, ocorreu um erro ao processar sua solicita√ß√£o."
    
    def _atualizar_stats_reflexao(self, reflexao):
        """Atualiza estat√≠sticas do Reflexor"""
        try:
            score_atual = reflexao.score_qualidade
            
            # Calcular m√©dia m√≥vel do score
            scores_anteriores = self.stats.get("score_medio_qualidade", 0.0)
            total_avaliacoes = self.stats.get("successful_interactions", 0) + 1
            
            nova_media = ((scores_anteriores * (total_avaliacoes - 1)) + score_atual) / total_avaliacoes
            self.stats["score_medio_qualidade"] = nova_media
            
        except Exception as e:
            logger.error(f"Erro ao atualizar stats: {e}")
    
    def _melhorar_resposta(self, mensagem: str, resposta: str, reflexao) -> Optional[str]:
        """Tenta melhorar resposta com base na an√°lise"""
        try:
            if self.reflexor and hasattr(self.reflexor, 'melhorar_resposta'):
                return self.reflexor.melhorar_resposta(mensagem, resposta)
        except Exception as e:
            logger.error(f"‚ö†Ô∏è Erro ao melhorar resposta: {e}")
        return None
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas completas v2.0"""
        stats = {
            "version": "2.0",
            "session_memory": {
                "conversations": len(self.conversa_memoria),
                "context_items": len(self.contexto_memoria)
            },
            "processing_stats": {
                "total_responses": self.stats.get("total_respostas", 0),
                "with_memory": self.stats.get("respostas_com_memoria", 0),
                "without_memory": self.stats.get("respostas_sem_memoria", 0),
                "semantic_searches": self.stats.get("busca_semantica_usado", 0),
                "context_retrieved": self.stats.get("contexto_recuperado", 0),
                "learnings_saved": self.stats.get("aprendizados_salvos", 0),
                "avg_quality_score": self.stats.get("score_medio_qualidade", 0.0)
            }
        }
        
        if self.memory_manager and self.memoria_ativa:
            try:
                vector_stats = self.memory_manager.get_stats()
                stats["vector_memory"] = vector_stats
            except Exception as e:
                stats["vector_memory"] = {"error": str(e)}
        
        return stats

# ===== FUN√á√ïES DE CRIA√á√ÉO v2.0 =====

def create_carlos() -> CarlosAgent:
    """Cria Carlos v2.0 b√°sico (sem Reflexor)"""
    return CarlosAgent(reflexor_ativo=False, memoria_ativa=True)

def create_carlos_com_reflexor(reflexor_ativo: bool = True, llm=None) -> CarlosAgent:
    """Cria Carlos v2.0 com Reflexor integrado"""
    return CarlosAgent(reflexor_ativo=reflexor_ativo, memoria_ativa=True, llm=llm)

def criar_carlos_integrado(supervisor_ativo: bool = True, reflexor_ativo: bool = True, llm=None):
    """Cria Carlos v2.0 completo (compatibilidade com app.py)"""
    return CarlosAgent(reflexor_ativo=reflexor_ativo, memoria_ativa=True, llm=llm)

def create_carlos_full_system(llm=None) -> CarlosAgent:
    """Cria Carlos v2.0 com todos os sistemas ativados"""
    return CarlosAgent(reflexor_ativo=True, memoria_ativa=True, llm=llm)

# ===== DIAGN√ìSTICO v2.0 =====

def diagnosticar_carlos():
    """Diagn√≥stica o Carlos v2.0"""
    try:
        carlos = create_carlos()
        
        return {
            "version": "2.0",
            "carlos_ok": True,
            "memoria_disponivel": carlos.memoria_ativa,
            "reflexor_integrado": hasattr(carlos, 'reflexor') and carlos.reflexor is not None,
            "memoria_ativa": hasattr(carlos, 'memory_manager') and carlos.memory_manager is not None,
            "config_ok": carlos.llm is not None,
            "stats": carlos.stats
        }
    except Exception as e:
        return {
            "version": "2.0",
            "carlos_ok": False,
            "erro": str(e)
        }

# ===== TESTE B√ÅSICO =====

if __name__ == "__main__":
    print("üß™ Testando Carlos v2.0...")
    diag = diagnosticar_carlos()
    print(f"üìä Diagn√≥stico v2.0: {diag}")
    
    if diag.get("carlos_ok"):
        print("‚úÖ Carlos v2.0 OK!")
        if diag.get("memoria_disponivel"):
            print("üß† Mem√≥ria vetorial dispon√≠vel!")
        else:
            print("‚ö†Ô∏è Mem√≥ria vetorial n√£o dispon√≠vel - instale: pip install chromadb sentence-transformers")
    else:
        print(f"‚ùå Erro: {diag.get('erro')}")
