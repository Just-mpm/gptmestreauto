"""
GPT MESTRE AUTÃ”NOMO - Agente Carlos (Interface Principal)
"""

from typing import Dict, Any, List
from datetime import datetime

from agents.base_agent import BaseAgent
from utils.logger import log_function_call

class CarlosAgent(BaseAgent):
    """
    Carlos - Agente de Interface Principal
    
    ResponsÃ¡vel por:
    - Conversar naturalmente com o usuÃ¡rio
    - Coordenar outros agentes quando necessÃ¡rio
    - Manter o contexto da conversa
    - Executar comandos bÃ¡sicos
    """
    
    def __init__(self):
        super().__init__(
            name="Carlos",
            role="Interface Principal e Coordenador",
        )
        
        # Comandos especiais que Carlos pode executar
        self.special_commands = {
            "/help": self._show_help,
            "/status": self._show_status,
            "/memory": self._show_memory,
            "/clear": self._clear_session,
            "/agents": self._list_agents,
        }
        
        self.logger.info("ğŸ¯ Carlos - Interface Principal ativado")
    
    def _default_personality(self) -> str:
        return """
        VocÃª Ã© Carlos, a interface principal do sistema GPT Mestre AutÃ´nomo.
        
        CARACTERÃSTICAS:
        - Conversador natural e amigÃ¡vel
        - Inteligente e prestativo
        - Capaz de executar tarefas complexas
        - Coordena outros agentes quando necessÃ¡rio
        - MantÃ©m contexto das conversas
        
        ESTILO DE COMUNICAÃ‡ÃƒO:
        - Use linguagem natural e acessÃ­vel
        - Seja proativo em sugerir soluÃ§Ãµes
        - Explique processos quando relevante
        - Mantenha tom profissional mas descontraÃ­do
        - Use emojis ocasionalmente para tornar a conversa mais amigÃ¡vel
        
        CAPACIDADES ESPECIAIS:
        - Pode executar comandos especiais (iniciados com /)
        - Acessa memÃ³ria do sistema
        - Coordena outros agentes (Reflexor, OrÃ¡culo, etc.)
        - Processa solicitaÃ§Ãµes complexas
        """
    
    @log_function_call
    async def process_message(self, message: str, context: Dict[str, Any] = None) -> str:
        """Processa mensagens do usuÃ¡rio"""
        
        # Verifica se Ã© um comando especial
        if message.startswith('/'):
            return await self._handle_special_command(message, context)
        
        # Atualiza contexto com informaÃ§Ãµes da sessÃ£o
        if not context:
            context = {}
        
        context.update({
            "timestamp": datetime.now().isoformat(),
            "user_message": message,
            "session_id": context.get("session_id", "default"),
        })
        
        # ConstrÃ³i prompt contextualizado
        prompt = self._build_contextual_prompt(message, context)
        
        # Processa com o LLM
        response = await self.think(prompt, context)
        
        # Adiciona assinatura se necessÃ¡rio
        if self._should_add_signature(response):
            response += "\n\n*â€” Carlos (GPT Mestre)*"
        
        return response
    
    def _build_contextual_prompt(self, message: str, context: Dict[str, Any]) -> str:
        """ConstrÃ³i prompt com contexto completo"""
        
        # HistÃ³rico recente (Ãºltimas 3 mensagens)
        recent_history = ""
        if len(self.memory.messages) > 0:
            recent_msgs = self.memory.messages[-3:]
            history_items = []
            for msg in recent_msgs:
                history_items.append(f"UsuÃ¡rio: {msg['input']}")
                history_items.append(f"Carlos: {msg['output']}")
            recent_history = "\n".join(history_items)
        
        # Contexto da sessÃ£o
        session_info = ""
        if context:
            session_info = f"SessÃ£o: {context.get('session_id', 'default')}"
            if context.get('user_name'):
                session_info += f" | UsuÃ¡rio: {context['user_name']}"
        
        prompt = f"""
        {session_info}
        
        HISTÃ“RICO RECENTE:
        {recent_history}
        
        MENSAGEM ATUAL DO USUÃRIO:
        {message}
        
        Responda como Carlos, considerando todo o contexto acima.
        Se a pergunta for complexa ou precisar de anÃ¡lise especÃ­fica, 
        considere mencionar que pode consultar outros agentes do sistema.
        """
        
        return prompt.strip()
    
    async def _handle_special_command(self, command: str, context: Dict[str, Any] = None) -> str:
        """Processa comandos especiais"""
        
        command_parts = command.split()
        base_command = command_parts[0]
        
        if base_command in self.special_commands:
            return await self.special_commands[base_command](command_parts[1:], context)
        else:
            return f"âŒ Comando '{base_command}' nÃ£o reconhecido. Use /help para ver comandos disponÃ­veis."
    
    async def _show_help(self, args: List[str], context: Dict[str, Any] = None) -> str:
        """Mostra ajuda dos comandos"""
        help_text = """
        ğŸ¤– **Comandos Especiais do Carlos:**
        
        `/help` - Mostra esta ajuda
        `/status` - Status do sistema
        `/memory` - InformaÃ§Ãµes da memÃ³ria
        `/clear` - Limpa a sessÃ£o atual
        `/agents` - Lista agentes disponÃ­veis
        
        **Exemplos de uso:**
        - "Analise este texto..." 
        - "Crie um plano para..."
        - "Me ajude com..."
        - "/status" (comando especial)
        
        Posso executar tarefas complexas e coordenar outros agentes quando necessÃ¡rio! ğŸš€
        """
        return help_text.strip()
    
    async def _show_status(self, args: List[str], context: Dict[str, Any] = None) -> str:
        """Mostra status do sistema"""
        memory_summary = self.get_memory_summary()
        
        # Verifica integraÃ§Ãµes configuradas
        integrations_status = []
        if hasattr(config, 'TELEGRAM_BOT_TOKEN') and config.TELEGRAM_BOT_TOKEN:
            integrations_status.append("ğŸ“± Telegram: Configurado (Fase 4)")
        else:
            integrations_status.append("ğŸ“± Telegram: NÃ£o configurado")
        
        if hasattr(config, 'NOTION_API_KEY') and config.NOTION_API_KEY:
            integrations_status.append("ğŸ“ Notion: Configurado (Fase 4)")
        else:
            integrations_status.append("ğŸ“ Notion: NÃ£o configurado")
        
        integrations_text = "\n        - ".join(integrations_status)
        
        status = f"""
        ğŸ“Š **Status do GPT Mestre AutÃ´nomo:**
        
        **Agente Carlos:**
        - âœ… Ativo e operacional
        - ğŸ’¬ Mensagens processadas: {memory_summary['total_messages']}
        - â° Ãšltima atualizaÃ§Ã£o: {memory_summary['last_updated'][:19]}
        
        **Sistema:**
        - ğŸ”§ VersÃ£o: {self.memory.context.get('system_version', 'v1.0.0')}
        - ğŸ§  Modelo: Mistral 7B (OpenRouter)
        - ğŸ“ Logs: Ativos
        
        **Agentes DisponÃ­veis:**
        - Carlos (Interface) âœ…
        - Reflexor (Em desenvolvimento) ğŸ”„
        - OrÃ¡culo (Em desenvolvimento) ğŸ”„
        
        **IntegraÃ§Ãµes:**
        - {integrations_text}
        """
        
        return status.strip()
    
    async def _show_memory(self, args: List[str], context: Dict[str, Any] = None) -> str:
        """Mostra informaÃ§Ãµes da memÃ³ria"""
        memory = self.get_memory_summary()
        
        memory_info = f"""
        ğŸ§  **MemÃ³ria do Carlos:**
        
        - **Total de interaÃ§Ãµes:** {memory['total_messages']}
        - **Criado em:** {memory['created_at'][:19]}
        - **Ãšltima atualizaÃ§Ã£o:** {memory['last_updated'][:19]}
        
        **Contexto atual:**
        {memory['context'] if memory['context'] else 'Nenhum contexto especÃ­fico'}
        
        **Ãšltimas 3 interaÃ§Ãµes:**
        """
        
        # Adiciona Ãºltimas mensagens
        if self.memory.messages:
            recent = self.memory.messages[-3:]
            for i, msg in enumerate(recent, 1):
                timestamp = msg['timestamp'][:19]
                memory_info += f"\n{i}. [{timestamp}] {msg['input'][:50]}..."
        else:
            memory_info += "\nNenhuma interaÃ§Ã£o anterior."
        
        return memory_info.strip()
    
    async def _clear_session(self, args: List[str], context: Dict[str, Any] = None) -> str:
        """Limpa a sessÃ£o atual"""
        self.clear_memory()
        return "ğŸ§¹ SessÃ£o limpa! ComeÃ§ando uma nova conversa."
    
    async def _list_agents(self, args: List[str], context: Dict[str, Any] = None) -> str:
        """Lista agentes disponÃ­veis"""
        agents_info = """
        ğŸ¤– **Agentes do GPT Mestre AutÃ´nomo:**
        
        **Carlos** (Interface Principal) âœ…
        - Conversa natural com usuÃ¡rios
        - Coordena outros agentes
        - Executa comandos especiais
        
        **Reflexor** (Auditor) ğŸ”„
        - Analisa e critica respostas
        - ValidaÃ§Ã£o de qualidade
        - SugestÃµes de melhoria
        
        **OrÃ¡culo** (Decisor) ğŸ”„
        - Toma decisÃµes estratÃ©gicas
        - AnÃ¡lise de contexto profundo
        - RecomendaÃ§Ãµes acionÃ¡veis
        
        **Status:** âœ… Ativo | ğŸ”„ Em desenvolvimento | âŒ Inativo
        """
        return agents_info.strip()
    
    def _should_add_signature(self, response: str) -> bool:
        """Determina se deve adicionar assinatura Ã  resposta"""
        # NÃ£o adiciona em comandos especiais ou respostas muito curtas
        if response.startswith(('ğŸ¤–', 'ğŸ“Š', 'ğŸ§ ', 'âŒ', 'ğŸ§¹')) or len(response) < 100:
            return False
        return True
    
    # MÃ©todo para integraÃ§Ã£o com outros agentes (Fase futura)
    async def consult_agent(self, agent_name: str, query: str) -> str:
        """Consulta outro agente (implementaÃ§Ã£o futura)"""
        self.logger.info(f"ğŸ”„ Consultando agente {agent_name}: {query[:50]}...")
        # Por enquanto, retorna uma resposta simulada
        return f"[Consulta ao {agent_name} serÃ¡ implementada na prÃ³xima fase]"

# Factory function
def create_carlos() -> CarlosAgent:
    """Cria uma instÃ¢ncia do agente Carlos"""
    return CarlosAgent()

if __name__ == "__main__":
    # Teste do Carlos
    print("ğŸ§ª Testando agente Carlos...")
    
    async def test_carlos():
        carlos = create_carlos()
        
        # Teste comandos especiais
        print("\n=== Testando comandos especiais ===")
        help_response = await carlos.process_message("/help")
        print("Help:", help_response[:100] + "...")
        
        status_response = await carlos.process_message("/status")
        print("Status:", status_response[:100] + "...")
        
        # Teste conversa normal
        print("\n=== Testando conversa normal ===")
        response = await carlos.process_message("OlÃ¡ Carlos, como vocÃª pode me ajudar?")
        print("Resposta:", response[:100] + "...")
        
        print("\nâœ… Teste do Carlos concluÃ­do!")
    
    # Descomente para testar (precisa da OPENAI_API_KEY configurada)
    # import asyncio
    # asyncio.run(test_carlos())
    print("âœ… Agente Carlos criado com sucesso!")