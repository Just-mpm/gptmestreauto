"""
GPT MESTRE AUTÃ”NOMO - Interface Chainlit APRIMORADA v5.0
ğŸš€ ETAPA 5: Interface e UX completa com todas as melhorias Gemini AI

Funcionalidades implementadas:
âœ… 15 Comandos Especiais Naturais
âœ… Sistema de Feedback Visual em ASCII  
âœ… Personalidade nas Respostas de Erro
âœ… Onboarding de 3 Passos para Novos UsuÃ¡rios
âœ… Sistema de OtimizaÃ§Ã£o Integrado
âœ… Monitoramento de Custos em Tempo Real
"""

import chainlit as cl
import asyncio
import threading
from datetime import datetime
import uuid
import os
import sys
import time

# Adicionar o diretÃ³rio ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Imports do sistema base
try:
    from config import config
    from agents.carlos import criar_carlos_maestro
    from utils.logger import get_logger
    
    # Imports das melhorias ETAPA 5
    from utils.natural_commands import get_natural_command_processor
    from utils.visual_feedback import get_visual_feedback_manager, ErrorDisplay
    from utils.onboarding_system import (
        get_onboarding_manager, check_and_start_onboarding, 
        process_message_with_onboarding
    )
    
    # Imports das otimizaÃ§Ãµes
    from utils.agent_orchestrator import get_agent_orchestrator
    from utils.token_monitor import get_token_monitor
    
    system_logger = get_logger("chainlit_enhanced")
    
except ImportError as e:
    print(f"âŒ Erro ao importar mÃ³dulos: {e}")
    exit(1)

# ConfiguraÃ§Ãµes do Chainlit
cl.config.name = "ğŸ§  GPT Mestre AutÃ´nomo v5.0 Enhanced"
cl.config.human_timeout = 300

# Estado global
carlos_instance = None
user_sessions = {}  # Gerenciar mÃºltiplas sessÃµes


class UserSession:
    """Classe para gerenciar estado de sessÃ£o do usuÃ¡rio"""
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.user_id = session_id[:8]  # Usar primeiros 8 chars como user_id
        self.start_time = datetime.now()
        self.message_count = 0
        self.onboarding_completed = False
        
        # Componentes de UX
        self.command_processor = get_natural_command_processor()
        self.feedback_manager = get_visual_feedback_manager()
        self.onboarding_manager = get_onboarding_manager()
        self.orchestrator = get_agent_orchestrator()
        self.token_monitor = get_token_monitor()
        
        system_logger.info(f"ğŸ‘¤ Nova sessÃ£o criada: {self.user_id}")


@cl.on_chat_start
async def start():
    """Inicializa o sistema com UX aprimorada"""
    global carlos_instance
    
    session_id = str(uuid.uuid4())
    user_session = UserSession(session_id)
    user_sessions[session_id] = user_session
    
    # Armazenar session_id no contexto do Chainlit
    cl.user_session.set("session_id", session_id)
    
    # Verificar se precisa de onboarding
    onboarding_message = check_and_start_onboarding(user_session.user_id)
    
    if onboarding_message:
        # UsuÃ¡rio novo - mostrar onboarding
        welcome_msg = cl.Message(
            content=onboarding_message,
            author="Carlos"
        )
        await welcome_msg.send()
        system_logger.info(f"ğŸ‘‹ Onboarding iniciado para {user_session.user_id}")
        
    else:
        # UsuÃ¡rio experiente - mensagem de boas-vindas rÃ¡pida
        welcome_content = """ğŸ‘‹ **Oi! Carlos aqui, pronto para mais uma sessÃ£o produtiva!**

ğŸš€ **Sistema 100% operacional** com todas as otimizaÃ§Ãµes ativas.

ğŸ’¡ **Dica rÃ¡pida**: 
â€¢ Use comandos naturais para economizar cota
â€¢ Digite *"Carlos, status"* para ver mÃ©tricas
â€¢ Digite *"Carlos, me ajuda"* se precisar de orientaÃ§Ã£o

**Como posso te ajudar hoje?** ğŸ˜Š"""
        
        welcome_msg = cl.Message(
            content=welcome_content,
            author="Carlos"  
        )
        await welcome_msg.send()
    
    # Inicializar Carlos se nÃ£o estiver ativo
    if not carlos_instance:
        try:
            # Mostrar feedback visual de inicializaÃ§Ã£o
            init_steps = ["Carregando MÃ³dulos", "Ativando Agentes", "Conectando APIs", "Sistema Pronto"]
            
            carlos_instance = criar_carlos_maestro(
                supervisor_ativo=True,
                reflexor_ativo=True,
                deepagent_ativo=True,
                oraculo_ativo=True,
                automaster_ativo=True,
                taskbreaker_ativo=True,
                psymind_ativo=True,
                promptcrafter_ativo=True,
                memoria_ativa=True,
                modo_proativo=True,
                inovacoes_ativas=True
            )
            
            system_logger.info(f"ğŸš€ Sistema inicializado para sessÃ£o {session_id}")
            
        except Exception as e:
            error_msg = cl.Message(
                content=f"âŒ Erro na inicializaÃ§Ã£o: {str(e)}\n\nTente recarregar a pÃ¡gina.",
                author="Sistema"
            )
            await error_msg.send()
            system_logger.error(f"âŒ Erro na inicializaÃ§Ã£o: {e}")


@cl.on_message
async def main(message: cl.Message):
    """Processa mensagens com UX aprimorada e todas as otimizaÃ§Ãµes"""
    global carlos_instance
    
    session_id = cl.user_session.get("session_id")
    if not session_id or session_id not in user_sessions:
        error_msg = cl.Message(
            content="âŒ SessÃ£o invÃ¡lida. Recarregue a pÃ¡gina.",
            author="Sistema"
        )
        await error_msg.send()
        return
    
    user_session = user_sessions[session_id]
    user_session.message_count += 1
    
    if not carlos_instance:
        ErrorDisplay.show_critical_error("Sistema nÃ£o inicializado")
        error_msg = cl.Message(
            content="âŒ Sistema nÃ£o inicializado. Recarregue a pÃ¡gina.",
            author="Carlos"
        )
        await error_msg.send()
        return
    
    user_input = message.content.strip()
    
    try:
        # ETAPA 1: Verificar se estÃ¡ em onboarding
        onboarding_response, should_process_normally = process_message_with_onboarding(
            user_input, user_session.user_id
        )
        
        if onboarding_response:
            response_msg = cl.Message(
                content=onboarding_response,
                author="Carlos"
            )
            await response_msg.send()
            
            if should_process_normally:
                user_session.onboarding_completed = True
                # Continuar processamento normal apÃ³s onboarding
            else:
                return  # Ainda em onboarding, nÃ£o processar mais
        
        # ETAPA 2: Verificar comandos especiais naturais
        command_response = user_session.command_processor.process_command(user_input)
        
        if command_response and command_response.is_handled:
            # Comando especial processado - resposta instantÃ¢nea
            
            # Mostrar feedback visual de resposta rÃ¡pida
            quick_indicator = user_session.feedback_manager.show_quick_response()
            
            # Adicionar mÃ©tricas ao final da resposta
            tokens_info = f"\n\nğŸ’ *Comando otimizado: {command_response.tokens_saved} tokens economizados*"
            final_content = command_response.content + tokens_info
            
            response_msg = cl.Message(
                content=final_content,
                author="Carlos"
            )
            await response_msg.send()
            
            system_logger.info(f"âš¡ Comando especial: {command_response.command_type}")
            return
        
        # ETAPA 3: Processamento normal com otimizaÃ§Ã£o
        
        # Mostrar feedback visual de processamento
        thinking_indicator = user_session.feedback_manager.show_thinking("Analisando sua solicitaÃ§Ã£o")
        
        # Obter mÃ©tricas antes do processamento
        before_usage = user_session.token_monitor.get_current_usage()
        tokens_before = before_usage['total_tokens']
        
        try:
            # Processar com orquestrador otimizado
            optimized_response = user_session.orchestrator.process_optimized(
                user_input, 
                context={"user_id": user_session.user_id}
            )
            
            # Parar indicador de pensamento
            thinking_indicator.stop()
            
            # Se usou agentes, mostrar feedback especÃ­fico
            if optimized_response.agents_used:
                agent_indicator = user_session.feedback_manager.show_agent_working(
                    ", ".join(optimized_response.agents_used), 
                    "finalizando"
                )
                await asyncio.sleep(0.5)  # Breve pausa para visibilidade
                agent_indicator.stop()
            
            # Mostrar sucesso
            user_session.feedback_manager.show_success()
            
            # Construir resposta final
            response_content = optimized_response.content
            
            # Adicionar mÃ©tricas se houver consumo ou economia significativa
            if optimized_response.tokens_used > 0 or optimized_response.tokens_saved > 50:
                metrics_info = f"\n\nğŸ“Š *"
                
                if optimized_response.tokens_used > 0:
                    metrics_info += f"{optimized_response.tokens_used} tokens â€¢ "
                
                if optimized_response.tokens_saved > 0:
                    metrics_info += f"ğŸ’ {optimized_response.tokens_saved} economizados â€¢ "
                
                metrics_info += f"âš¡ {optimized_response.total_execution_time:.1f}s"
                
                if optimized_response.optimization_applied:
                    metrics_info += f" â€¢ ğŸ”§ {', '.join(optimized_response.optimization_applied)}"
                
                metrics_info += "*"
                response_content += metrics_info
            
            # Enviar resposta
            response_msg = cl.Message(
                content=response_content,
                author="Carlos"
            )
            await response_msg.send()
            
            # Log da interaÃ§Ã£o
            system_logger.info(f"âœ… Resposta otimizada: {optimized_response.complexity_detected.value}")
            
        except Exception as processing_error:
            # Parar indicadores
            thinking_indicator.stop()
            
            # Mostrar erro com personalidade
            if "timeout" in str(processing_error).lower():
                ErrorDisplay.show_timeout_error()
                error_content = "â° **Timeout!** Um dos agentes demorou demais para responder. Que tal tentar uma pergunta mais simples ou aguardar um momento?"
            
            elif "api" in str(processing_error).lower():
                ErrorDisplay.show_api_error()
                error_content = "ğŸ”Œ **Problema de ConexÃ£o!** Houve um contratempo com os serviÃ§os externos. Vamos tentar novamente?"
            
            else:
                ErrorDisplay.show_critical_error(str(processing_error))
                error_content = "ğŸš¨ **Oops!** Tive um pequeno curto-circuito. Pode reformular sua pergunta?"
            
            error_msg = cl.Message(
                content=error_content,
                author="Carlos"
            )
            await error_msg.send()
            
            system_logger.error(f"âŒ Erro no processamento: {processing_error}")
        
    except Exception as e:
        # Erro crÃ­tico - mostrar personalidade do Carlos
        ErrorDisplay.show_critical_error(str(e))
        
        error_msg = cl.Message(
            content="ğŸ¤– **Carlos estÃ¡ confuso!** Algo inesperado aconteceu. Pode tentar de novo com uma pergunta diferente?",
            author="Carlos"
        )
        await error_msg.send()
        
        system_logger.error(f"âŒ Erro crÃ­tico: {e}")


@cl.on_stop
async def stop():
    """Limpa recursos quando o chat para"""
    global carlos_instance
    
    session_id = cl.user_session.get("session_id")
    if session_id and session_id in user_sessions:
        user_session = user_sessions[session_id]
        
        # Parar todos os indicadores visuais
        user_session.feedback_manager.stop_all_indicators()
        
        # Log da sessÃ£o
        duration = datetime.now() - user_session.start_time
        system_logger.info(
            f"ğŸ›‘ SessÃ£o {user_session.user_id} encerrada: "
            f"{user_session.message_count} mensagens, {duration.total_seconds():.0f}s"
        )
        
        # Limpar sessÃ£o
        del user_sessions[session_id]
    
    # NÃ£o limpar carlos_instance - pode ser usado por outras sessÃµes


# Comando personalizado para mostrar dashboard completo
@cl.action_callback("show_dashboard")
async def show_dashboard_action(action):
    """AÃ§Ã£o para mostrar dashboard completo"""
    try:
        from utils.dashboard_display import get_dashboard_summary
        
        monitor = get_token_monitor()
        usage = monitor.get_current_usage()
        prediction = monitor.predict_monthly_cost()
        
        dashboard_content = f"""
ğŸ“Š **Dashboard Completo - GPT Mestre AutÃ´nomo**

**ğŸ’° Custos e Consumo Atual:**
â€¢ Tokens consumidos: {usage['total_tokens']:,}
â€¢ Custo atual: R$ {usage['estimated_cost_brl']:.2f}
â€¢ % da cota Max 5x: {usage['quota_percentage']:.1f}%
â€¢ Velocidade: {usage['tokens_per_minute']:.0f} tokens/min

**ğŸ“ˆ PrevisÃµes:**
â€¢ Custo diÃ¡rio: R$ {prediction['daily_cost_brl']:.2f}
â€¢ Custo mensal: R$ {prediction['monthly_cost_brl']:.2f}

**ğŸ”¥ Top 3 Agentes:**"""
        
        for i, (agent, data) in enumerate(usage['top_consumers'][:3], 1):
            dashboard_content += f"\n{i}. {agent}: {data['total_tokens']:,} tokens (R$ {data['cost_brl']:.2f})"
        
        # Adicionar alertas se houver
        if usage.get('alerts'):
            latest_alert = usage['alerts'][-1]
            dashboard_content += f"\n\nâš ï¸ **Ãšltimo Alerta:**\n{latest_alert['message']}"
        
        dashboard_content += f"\n\nğŸ’¡ {get_dashboard_summary()}"
        
        dashboard_msg = cl.Message(
            content=dashboard_content,
            author="Sistema de Monitoramento"
        )
        await dashboard_msg.send()
        
    except Exception as e:
        error_msg = cl.Message(
            content=f"âŒ Erro ao gerar dashboard: {str(e)}",
            author="Sistema"
        )
        await error_msg.send()


# Adicionar aÃ§Ãµes personalizadas na interface
@cl.on_chat_start
async def setup_actions():
    """Configura aÃ§Ãµes personalizadas na interface"""
    
    # AÃ§Ã£o para mostrar dashboard
    dashboard_action = cl.Action(
        name="show_dashboard",
        label="ğŸ“Š Dashboard",
        description="Mostrar dashboard completo de custos e uso"
    )
    
    # AÃ§Ã£o para comandos de ajuda
    help_action = cl.Action(
        name="show_help", 
        label="ğŸ†˜ Ajuda",
        description="Mostrar comandos disponÃ­veis"
    )
    
    # AÃ§Ã£o para status rÃ¡pido
    status_action = cl.Action(
        name="quick_status",
        label="âš¡ Status",
        description="Status rÃ¡pido do sistema"
    )
    
    await cl.Message(
        content="ğŸ›ï¸ **AÃ§Ãµes rÃ¡pidas disponÃ­veis nos botÃµes acima**",
        actions=[dashboard_action, help_action, status_action]
    ).send()


@cl.action_callback("show_help")
async def show_help_action(action):
    """AÃ§Ã£o para mostrar ajuda"""
    help_content = """
ğŸ†˜ **Guia RÃ¡pido - GPT Mestre AutÃ´nomo v5.0**

**ğŸ¯ Comandos Naturais (Economizam Cota):**
â€¢ *"Carlos, como estÃ¡ o sistema?"* - Status completo
â€¢ *"Carlos, quem estÃ¡ por aÃ­?"* - Lista de agentes
â€¢ *"Carlos, quanto gastei hoje?"* - Uso da cota
â€¢ *"Carlos, me ajuda com [tÃ³pico]"* - Ajuda especÃ­fica
â€¢ *"Carlos, seja mais conciso"* - Ajustar verbosidade
â€¢ *"Carlos, modo criativo"* - Ativar modo criativo

**ğŸš€ Exemplos de Uso:**
â€¢ *"Analise o mercado de [produto]"* - DeepAgent + Scout
â€¢ *"Crie um prompt de vendas"* - PromptCrafter
â€¢ *"Me ajude a decidir entre X e Y"* - OrÃ¡culo
â€¢ *"Estou me sentindo ansioso"* - PsyMind

**ğŸ’¡ Dicas de OtimizaÃ§Ã£o:**
â€¢ Comandos como este nÃ£o gastam sua cota Max 5x
â€¢ Seja especÃ­fico para melhores resultados
â€¢ Use feedback para me ajudar a melhorar
â€¢ Sistema jÃ¡ otimiza automaticamente para economia

**ğŸ¨ Interface:**
â€¢ Use os botÃµes de aÃ§Ã£o rÃ¡pida acima
â€¢ Feedback visual mostra o que estÃ¡ acontecendo
â€¢ MÃ©tricas aparecem automaticamente nas respostas

**ğŸ”§ Em caso de problemas:**
â€¢ Recarregue a pÃ¡gina se algo nÃ£o funcionar
â€¢ Use *"Carlos, tenho um feedback"* para reportar issues
â€¢ Errors tÃªm personalidade - Carlos te orienta!
    """
    
    help_msg = cl.Message(
        content=help_content,
        author="Sistema de Ajuda"
    )
    await help_msg.send()


@cl.action_callback("quick_status") 
async def quick_status_action(action):
    """AÃ§Ã£o para status rÃ¡pido"""
    try:
        monitor = get_token_monitor()
        usage = monitor.get_current_usage()
        
        status_emoji = "ğŸŸ¢" if usage['quota_percentage'] < 70 else "ğŸŸ¡" if usage['quota_percentage'] < 90 else "ğŸ”´"
        
        quick_status = f"""
{status_emoji} **Status RÃ¡pido**

ğŸ“Š **Cota**: {usage['quota_percentage']:.1f}% usada
ğŸ’° **Custo**: R$ {usage['estimated_cost_brl']:.2f}
ğŸ¤– **Agentes**: Todos operacionais
âš¡ **Sistema**: Otimizado e funcionando

{get_dashboard_summary()}
        """.strip()
        
        status_msg = cl.Message(
            content=quick_status,
            author="Monitor do Sistema"
        )
        await status_msg.send()
        
    except Exception as e:
        error_msg = cl.Message(
            content="âš¡ **Sistema Operacional!** Monitor temporariamente indisponÃ­vel, mas tudo funcionando.",
            author="Carlos"
        )
        await error_msg.send()


if __name__ == "__main__":
    print("ğŸš€ Iniciando GPT Mestre AutÃ´nomo v5.0 Enhanced...")
    print("ğŸ“‹ Funcionalidades ETAPA 5 ativas:")
    print("   âœ… 15 Comandos Especiais Naturais")
    print("   âœ… Sistema de Feedback Visual ASCII")
    print("   âœ… Personalidade em Respostas de Erro")
    print("   âœ… Onboarding de 3 Passos")
    print("   âœ… Sistema de OtimizaÃ§Ã£o Completo")
    print("   âœ… Monitoramento de Custos em Tempo Real")
    print("ğŸŒŸ Interface e UX otimizada para Claude Max 5x!")
    
    cl.run()