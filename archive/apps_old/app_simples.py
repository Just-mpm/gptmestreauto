"""
GPT MESTRE AUTÃ”NOMO - Interface Chainlit SIMPLES
ğŸ¤– Apenas Carlos responde - Sistema silencioso e eficiente
"""

import chainlit as cl
import asyncio
from datetime import datetime
import uuid
import os
import sys

# Adicionar o diretÃ³rio ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Imports do sistema
try:
    from config import config
    from agents.carlos import criar_carlos_maestro
    from utils.logger import get_logger
    
    system_logger = get_logger("chainlit_simples")
    
except ImportError as e:
    print(f"âŒ Erro ao importar mÃ³dulos: {e}")
    exit(1)

# ConfiguraÃ§Ãµes do Chainlit
cl.config.name = "ğŸ§  GPT Mestre AutÃ´nomo v5.0"
cl.config.human_timeout = 300  # 5 minutos para operaÃ§Ãµes complexas

# Estado global
carlos_instance = None

@cl.on_chat_start
async def start():
    """Inicializa o sistema de forma simples e rÃ¡pida"""
    global carlos_instance
    
    session_id = str(uuid.uuid4())[:8]
    
    # Mensagem simples de inicializaÃ§Ã£o
    loading_msg = cl.Message(content="ğŸš€ Inicializando GPT Mestre AutÃ´nomo...")
    await loading_msg.send()
    
    try:
        # Inicializar Carlos com todos os sistemas
        carlos_instance = criar_carlos_maestro(
            supervisor_ativo=True,
            reflexor_ativo=True,
            deepagent_ativo=True,
            oraculo_ativo=True,
            automaster_ativo=True,
            taskbreaker_ativo=True,
            psymind_ativo=True,
            promptcrafter_ativo=True,
            memoria_ativa=True,
            modo_proativo=True,
            inovacoes_ativas=True  # Ativar as 10 inovaÃ§Ãµes
        )
        
        # Apagar mensagem de loading
        await loading_msg.remove()
        
        # Mensagem de boas-vindas simples
        welcome_msg = cl.Message(
            content=f"""
ğŸ‰ **GPT Mestre AutÃ´nomo v5.0 Pronto!**

OlÃ¡! Sou Carlos, seu assistente inteligente. Posso ajudar com:

â€¢ ğŸ’¡ AnÃ¡lises e estratÃ©gias
â€¢ ğŸ¯ Planejamento de projetos e carreira
â€¢ ğŸš€ AutomaÃ§Ã£o e otimizaÃ§Ã£o
â€¢ ğŸ¨ CriaÃ§Ã£o de conteÃºdo e prompts
â€¢ ğŸ” Pesquisas e insights
â€¢ ğŸ§  DecisÃµes complexas

**Como posso ajudar vocÃª hoje?** ğŸ˜Š
""",
            author="Carlos"
        )
        
        await welcome_msg.send()
        system_logger.info(f"ğŸš€ Sistema inicializado - SessÃ£o {session_id}")
        
    except Exception as e:
        error_msg = cl.Message(
            content=f"âŒ Erro na inicializaÃ§Ã£o: {str(e)}\n\nTente recarregar a pÃ¡gina."
        )
        await error_msg.send()
        system_logger.error(f"âŒ Erro na inicializaÃ§Ã£o: {e}")

@cl.on_message
async def main(message: cl.Message):
    """Processa mensagens de forma simples e direta"""
    global carlos_instance
    
    if not carlos_instance:
        error_msg = cl.Message(content="âŒ Sistema nÃ£o inicializado. Recarregue a pÃ¡gina.")
        await error_msg.send()
        return
    
    user_input = message.content.strip()
    
    # Verificar comandos especiais
    if user_input.lower() == "/status":
        try:
            from utils.dashboard_display import get_dashboard_summary
            from utils.token_monitor import get_token_monitor
            
            monitor = get_token_monitor()
            usage = monitor.get_current_usage()
            prediction = monitor.predict_monthly_cost()
            
            status_content = f"""
ğŸ“Š **Status do Sistema - GPT Mestre AutÃ´nomo**

**ğŸ’° Custos e Consumo:**
â€¢ Tokens consumidos: {usage['total_tokens']:,}
â€¢ Custo atual: R$ {usage['estimated_cost_brl']:.2f}
â€¢ % da cota Max 5x: {usage['quota_percentage']:.1f}%
â€¢ Velocidade: {usage['tokens_per_minute']:.0f} tokens/min

**ğŸ“ˆ PrevisÃµes:**
â€¢ Custo diÃ¡rio: R$ {prediction['daily_cost_brl']:.2f}
â€¢ Custo mensal: R$ {prediction['monthly_cost_brl']:.2f}

**ğŸ”¥ Top 3 Agentes:**"""
            
            for i, (agent, data) in enumerate(usage['top_consumers'][:3], 1):
                status_content += f"\n{i}. {agent}: {data['total_tokens']:,} tokens (R$ {data['cost_brl']:.2f})"
            
            # Adicionar alertas se houver
            if usage.get('alerts'):
                latest_alert = usage['alerts'][-1]
                status_content += f"\n\nâš ï¸ **Ãšltimo Alerta:**\n{latest_alert['message']}"
            
            status_content += f"\n\nğŸ’¡ {get_dashboard_summary()}"
            
            status_msg = cl.Message(
                content=status_content,
                author="Sistema"
            )
            await status_msg.send()
            return
            
        except Exception as e:
            error_msg = cl.Message(content=f"âŒ Erro ao obter status: {str(e)}")
            await error_msg.send()
            return
    
    elif user_input.lower() == "/help":
        help_content = """
ğŸ†˜ **Comandos DisponÃ­veis:**

â€¢ `/status` - Mostra dashboard de monitoramento
â€¢ `/help` - Esta mensagem de ajuda

**ğŸ’¡ Como usar:**
Digite suas perguntas normalmente. O sistema tem:
â€¢ ğŸ¤– Carlos Maestro - Coordenador principal
â€¢ ğŸ”® OrÃ¡culo - AnÃ¡lises profundas
â€¢ ğŸ§  DeepAgent - RaciocÃ­nio avanÃ§ado
â€¢ ğŸª Reflexor - AutocrÃ­tica e melhoria
â€¢ ğŸ¯ Supervisor - CoordenaÃ§Ã£o estratÃ©gica
â€¢ ğŸ¨ PromptCrafter - Engenharia de prompts
â€¢ ğŸ’­ PsyMind - AnÃ¡lise comportamental
â€¢ âš¡ Cache inteligente - Economia automÃ¡tica

**ğŸš€ Exemplos:**
"Analise esta situaÃ§Ã£o complexa..."
"Crie um plano estratÃ©gico para..."
"Me ajude a resolver este problema..."
"""
        help_msg = cl.Message(content=help_content, author="Sistema")
        await help_msg.send()
        return
    
    # Indicador simples de processamento
    thinking_msg = cl.Message(content="ğŸ¤” Pensando...")
    await thinking_msg.send()
    
    try:
        # Obter stats antes do processamento
        from utils.token_monitor import get_token_monitor
        monitor = get_token_monitor()
        before_usage = monitor.get_current_usage()
        tokens_before = before_usage['total_tokens']
        
        # Processar com Carlos (ele gerencia tudo internamente)
        response = carlos_instance.processar(user_input, {})
        
        # Obter stats depois
        after_usage = monitor.get_current_usage()
        tokens_after = after_usage['total_tokens']
        tokens_used = tokens_after - tokens_before
        
        # Remover indicador
        await thinking_msg.remove()
        
        # Enviar resposta do Carlos
        response_content = response
        
        # Adicionar mÃ©tricas se houver consumo
        if tokens_used > 0:
            response_content += f"\n\nğŸ“Š *{tokens_used} tokens â€¢ R$ {after_usage['cost_per_request']:.2f} â€¢ {after_usage['quota_percentage']:.1f}% da cota*"
        
        response_msg = cl.Message(
            content=response_content,
            author="Carlos"
        )
        await response_msg.send()
        
        system_logger.info(f"âœ… Resposta gerada para: {user_input[:50]}...")
        
    except Exception as e:
        # Remover indicador
        await thinking_msg.remove()
        
        # Mensagem de erro amigÃ¡vel
        if "timeout" in str(e).lower():
            error_content = "Desculpe, estou temporariamente indisponÃ­vel. Por favor, tente novamente em alguns momentos."
        else:
            error_content = "Desculpe, nÃ£o consegui processar sua mensagem. Pode tentar reformular?"
        
        error_msg = cl.Message(
            content=error_content,
            author="Carlos"
        )
        await error_msg.send()
        system_logger.error(f"âŒ Erro no processamento: {e}")

@cl.on_stop
async def stop():
    """Limpa recursos quando o chat para"""
    global carlos_instance
    carlos_instance = None
    system_logger.info("ğŸ›‘ SessÃ£o encerrada")

if __name__ == "__main__":
    cl.run()